---
title: "Supplemental Figure 4"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format:
  html:
    embed-resources: true
    code-fold: show
params:
  fig.path: "`r paste0(params$fig.path)`" #./Figures/
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.width     = 6.6929133858,
  fig.path      = params$fig.path,#"../Figures/",
  fig.align     = "center",
  message       = FALSE,
  warning       = FALSE,
  dev           = c("png"),
  dpi           = 300,
  fig.process = function(filename){
    new_filename <- stringr::str_remove(string = filename,
                                        pattern = "-1")
    fs::file_move(path = filename, new_path = new_filename)
    ifelse(fs::file_exists(new_filename), new_filename, filename)
  }
  )
# setwd("/Users/vilkal/work/Brolidens_work/Projects/Spatial_DMPA/src/manuscript")
```

```{r background_job, eval=FALSE, include=FALSE}
source("../bin/render_with_jobs.R")

# quarto
# render_html_with_job(out_dir = lab_dir)
# fs::file_move(path = file, new_path = paste0(lab_dir, file))

# currently using quarto for github and kniter for html due to source code option 
render_git_with_job(fig_path = "./Figures/S1/")
system2(command = "sed", stdout = TRUE,
        args = c("-i", "''","-e", 's/src=\\"\\./src=\\"\\.\\./g',
                 paste0("./md_files/", basename("./S1_figures.md"))))

# kniter
knit_html_with_job(out_dir = "../lab_book/09_figures", fig_path = "./Figures/S1/")
```

### Load data and libraries
```{r Load_data}
##################
# LOAD LIBRARIES #
##################
library(tidyverse)
library(Seurat)
library(SeuratObject)
library(tidyseurat)
library(ggpubr)

#########
# PATHS #
#########
input_dir <- "../../results/04_deconvolution_st_data/"
result_dir <- "../../results/09_figures/"
if( isFALSE(dir.exists(result_dir)) ) { dir.create(result_dir,recursive = TRUE) }
epi_clus <- "^5$|^6$|^7|^9" # non-filt

#################
# DOWNLOAD DATA #
#################
## TRX DATA:
GEO_url <- "https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE194276&format=file&file=GSE194276%5FRaw%5Fgene%5Fcounts%5Fmatrix%2Ecsv%2Egz"
# download.file(GEO_url, paste0("../data/"," Raw_gene_counts_matrix.csv.gz"), method="auto")
# system("gunzip ../data/*.gz")

#############
# LOAD DATA #
#############
DATA <- readRDS(paste0(input_dir,"seuratObj_deconvolution_scdc.RDS"))
trx_csv <- read_csv(paste0("/Users/vilkal/Raw_data/Bulk_Transcriptomics/Visit_3/Raw_counts_matrix_v3",".csv"))
```

```{r suppl-fig-4}
###########################
# SPATIAL PSEUDOBULK DATA #
###########################
# get the count matrix for all cells
  sparse_mtrx <- DATA@assays$RNA@counts
# Compute pseudobulk
  mm <- Matrix::sparse.model.matrix(~0 + DATA$orig.ident)
  pseudobulk <- sparse_mtrx %*% mm
  colnames(pseudobulk) <- str_extract(colnames(pseudobulk), "P\\d\\d\\d")
  pseudobulk <- pseudobulk[, sample_id]
  
  # define the groups
  bulk.labels = groups
  
  dge.list <- DGEList(counts = pseudobulk)
  keep <- filterByExpr(dge.list)
  #dge.list <- dge.list[keep, , keep.lib.sizes = FALSE]
  
  dge.list <- calcNormFactors(dge.list)
  cpm <- cpm(dge.list, log=T) %>% as_tibble(., rownames = "symbol")

#############
# BULK DATA #
#############
sample_id <- c("P107", "P108", "P114", "P097","P118", "P105", "P080", "P031") %>% set_names()

bulk <- trx_csv %>% 
  select(symbol, all_of(sample_id)) %>%
  filter(rowSums(across(where(is.numeric)))!=0) %>%
  filter(!(is.na(.$symbol))) #%>%
  #filter(symbol %in% cpm$symbol)

# check for duplicated symbols
bulk %>% group_by(symbol) %>% summarize(n(), .groups='drop_last') %>% filter(`n()`>1)  %>% .$symbol

bulk_norm <- DGEList(bulk[,2:9], genes = bulk$symbol) %>%
  calcNormFactors(method = "TMM") %>%
  cpm(log=T) %>%
  as_tibble() %>%
  bind_cols(symbol = bulk$symbol, .) 

comp <- map(sample_id, ~full_join(select(cpm, symbol, ST_data=.x), select(bulk_norm, symbol, bulk_data=.x)) ) %>%
  bind_rows(., .id = "sample") %>%
  mutate(sample = factor(.$sample, levels = sample_id))


ggplot( comp, aes( y=ST_data, x=bulk_data ))+ 
  geom_point(pch = 1)+ 
  stat_cor(method = "pearson") + # , label.x = -0.5, label.y = 15
  geom_smooth(method=lm) + 
  #stat_regline_equation(color="blue", label.y = 13) +#geom_ +
  facet_wrap("sample", ncol = 4, strip.position = "top", shrink = F) +
  theme_light() + theme(text = element_text(size = 17)) 

```